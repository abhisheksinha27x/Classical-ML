{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a30807a",
   "metadata": {},
   "source": [
    "The goal is to split our dataset into training and test sets in a way that ensures:\n",
    "- we don't train on the test set (to prevent data snooping bias)\n",
    "- the test set is representative of the overall data (important for generalization)\n",
    "- and this split is stable and reproducible over time\n",
    "\n",
    "### Why do we need a test set?\n",
    "A test set simulates new, unseen data and helps us to estimate how our model will perform in the real world.\n",
    "- Training set - used to train the model\n",
    "- Test set - used to evaluate final performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f11019",
   "metadata": {},
   "source": [
    "## The Naive Way (Not Ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "housing = pd.read_csv(\"datasets/housing/housing.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a91dd",
   "metadata": {},
   "source": [
    "- This splits 80% of the data into `train_set` and 20% into `test_set`\n",
    "- It works, but it has two problems:\n",
    "    - It's random -> the test set changes each time unless you fix `random_state`\n",
    "    - It doesn't guarantee that the test set is __representative__ (e.g., of income distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9042e",
   "metadata": {},
   "source": [
    "## Better Approach: Stable Test Set Using Hashing\n",
    "It means creating a __consistent test split__ using a __hash function__. But Why?\n",
    "- Our dataset grows over time (more rows)\n",
    "- If we split randomly each time, some previously used test examples may end up in training -- __causing data leakage__.\n",
    "\n",
    ">The Solution:\n",
    "use a rowID or index and a hash function to deterministically select test set rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33430be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833598b",
   "metadata": {},
   "source": [
    "- `identifier` = unique ID per row\n",
    "- `hash()` = hash function lilke `hashlib`.md5\n",
    "- it keeps rows in the test set if their hash value is in the lowest `test_ratio` portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8edeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e973bd3",
   "metadata": {},
   "source": [
    "This approach:\n",
    "- always puts the same rows into test set, even when the dataset is updated later\n",
    "- avoids data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459312d",
   "metadata": {},
   "source": [
    "## Problem: What if We Don't Have a Row ID?\n",
    "Use a combination of features to generate one, or use the row index itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bee67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id = housing.reset_index() # adds index as a column\n",
    "# now we can use that index as the indentifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d18a45",
   "metadata": {},
   "source": [
    "## Best Practice: Stratified Sampling\n",
    "Random sampling can still give us a test set that's not representative, especially for skewed features like income.<br>\n",
    "So we will use __Stratified Sampling__ using income category as the __stratification feature__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db031a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing['income_cat']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab876fe",
   "metadata": {},
   "source": [
    "- This ensures the distribution of income_cat is the same in both training and test sets.\n",
    "- Much better for realistic performance estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e5428",
   "metadata": {},
   "source": [
    "## Let's build a solid understanding of Stratified Sampling\n",
    "\n",
    "> Stratified Sampling is a technique where we split the data into groups (strata) based on an important feature, then sample proportionally from each group.\n",
    "\n",
    "__Why?__<br>\n",
    "To ensure the sample (like a test set) has the same distribution of key characteristics as the full dataset -- so it's fair and representative\n",
    "\n",
    "__Context:__ <br>\n",
    "We're building a model to predict median house value. One of the most important input features is:\n",
    "> `median_income`, But it is not evenly distributed -- there are many low-income districts, fewer high-income ones.\n",
    "\n",
    "__Problem with Random Splits:__ <br>\n",
    "If we split randomly, it may pick too few high-income districts in the test set -- so the test ste won't reflect how well the model works for all income levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f8601",
   "metadata": {},
   "source": [
    "__Solution: Use Stratified Sampling on Income__\n",
    "1. convert `median_income` into income categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f816a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = pd.cut(\n",
    "    housing[\"median_income\"],\n",
    "    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "    labels=[1, 2, 3, 4, 5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82eef6",
   "metadata": {},
   "source": [
    "This turns continuous income into 5 categories, like:\n",
    "| Category | Income Range |\n",
    "| -------- | ------------ |\n",
    "| 1        | 0.0 – 1.5    |\n",
    "| 2        | 1.5 – 3.0    |\n",
    "| 3        | 3.0 – 4.5    |\n",
    "| 4        | 4.5 – 6.0    |\n",
    "| 5        | 6.0+         |\n",
    "\n",
    "2. Apply `StratifiedShuffleSplit` to maintain the same ratio of each income group in train and test sets.\n",
    "3. Now, our training and test sets both reflect the income structure of the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80792eaa",
   "metadata": {},
   "source": [
    "## What do to after this?\n",
    "- remove the `income_cat` column -- it was just for stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4b0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e0d3e",
   "metadata": {},
   "source": [
    "- Now move on to:\n",
    "    - Data exploration\n",
    "    - Feature engineering\n",
    "    - Model building -- with balanced and representative train/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2ec8c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52caf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is random splitting, which can lead to biased or unbalanced test sets, especially if important features (like income) are not evenly distributed.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10564f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is a categorical version of median income, which helps us later do stratified sampling — ensuring every income group is proportionally represented in both train and test sets.\n",
    "\n",
    "housing['income_cat'] = pd.cut(housing['median_income'], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ddf4f",
   "metadata": {},
   "source": [
    "| Method                     | Purpose                                                                                 | When to Use                                                                       |\n",
    "| -------------------------- | --------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |\n",
    "| `train_test_split()`       | Randomly splits data into train/test                                                    | Use only for quick tests or when you’re sure your data is evenly distributed.     |\n",
    "| `StratifiedShuffleSplit()` | Splits data **while preserving the distribution** of an important feature (like income) | ✅ Use this when your data is **not evenly distributed**, especially for ML tasks. |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classical ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
