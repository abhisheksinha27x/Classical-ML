

## ðŸ”„ What is a Transformation Pipeline?

A **pipeline** in machine learning is a **sequence of data processing steps** chained together â€” each step transforms the data and passes it to the next.

In scikit-learn, the `Pipeline` class helps:

* Automate workflows (clean, consistent structure)
* Reduce bugs (less manual code)
* Support cross-validation and model tuning

---

### âœ… Why Use a Pipeline?

Without a pipeline, your code may look like this:

```python
# manual steps
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

model = LogisticRegression()
model.fit(X_pca, y)
```

This is error-prone and doesn't integrate well with cross-validation or grid search.

Instead, with a pipeline:

```python
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=2)),
    ('classifier', LogisticRegression())
])

pipeline.fit(X, y)
```

---

## ðŸ§± Structure of a Pipeline

```python
Pipeline([
    ('step_name_1', transformer_1),
    ('step_name_2', transformer_2),
    ...
    ('final_step', estimator)  # Final step must be an estimator (with `.fit()`)
])
```

### ðŸ”§ What qualifies as a transformer or estimator?

* **Transformers** must have: `.fit()` and `.transform()`
  e.g., `StandardScaler`, `OneHotEncoder`, `SimpleImputer`

* **Estimators** must have: `.fit()` and `.predict()`
  e.g., `LinearRegression`, `RandomForestClassifier`

---

## ðŸ’¡ How Pipelines Work

Under the hood:

1. `pipeline.fit(X, y)`

   * Calls `.fit_transform()` on all transformers (except last step)
   * Calls `.fit()` on the final estimator

2. `pipeline.predict(X)`

   * Applies `.transform()` of all steps (except last)
   * Calls `.predict()` on the final estimator

---

## ðŸ“¦ Real Example: California Housing Dataset

Suppose you want to:

* Fill missing values
* Standardize numeric features
* Train a model

```python
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression

housing_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('regressor', LinearRegression())
])

housing_pipeline.fit(housing_num, housing_labels)
preds = housing_pipeline.predict(housing_num)
```

---

## ðŸ§  Benefits of Pipelines

| Feature         | Benefit                                                    |
| --------------- | ---------------------------------------------------------- |
| Clean workflow  | All steps are in one object                                |
| Reproducibility | Consistent behavior during train and test                  |
| Integration     | Works with `GridSearchCV`, `cross_val_score`, etc.         |
| No data leakage | Fit transformers only on training data during CV           |
| Customization   | You can insert your own transformers (even custom classes) |

---

## ðŸ”€ Pipelines with Multiple Columns: `ColumnTransformer`

You can apply different pipelines to different columns:

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

full_pipeline = ColumnTransformer([
    ('num', num_pipeline, numeric_features),
    ('cat', OneHotEncoder(), categorical_features)
])

# Final full pipeline with model
final_pipeline = Pipeline([
    ('preprocessing', full_pipeline),
    ('model', LinearRegression())
])
```

---

## âœ… Summary

| Concept          | Description                                              |
| ---------------- | -------------------------------------------------------- |
| **Pipeline**     | Sequence of transformers + final estimator               |
| **Transformers** | Do preprocessing (e.g., scaling, imputation)             |
| **Estimator**    | Final model that learns/predicts                         |
| **fit()**        | Runs `.fit_transform()` on all steps, `.fit()` on final  |
| **predict()**    | Runs `.transform()` then `.predict()`                    |
| **Benefits**     | Clean code, fewer bugs, CV-compatible, modular, reusable |

---
